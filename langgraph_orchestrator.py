"""
LangGraph ç‰ˆæœ¬çš„å¤šæ™ºèƒ½ä½“ç¼–æ’ç³»ç»Ÿ | LangGraph Version of Multi-Agent Orchestration System
ä½¿ç”¨ LangGraph çš„çŠ¶æ€å›¾æ¥ç®¡ç†Agentçš„æ‰§è¡Œæµç¨‹
Uses LangGraph's state graph to manage the execution flow of agents
"""

from typing import TypedDict, List, Any, Dict
from datetime import datetime
import json
from langgraph.graph import StateGraph, END
from logger_config import logger, log_function_call


class OrchestratorState(TypedDict):
    """
    ç¼–æ’å™¨çš„çŠ¶æ€å®šä¹‰ | State definition for the Orchestrator
    ç”¨äºåœ¨å„ä¸ªAgentä¹‹é—´ä¼ é€’ä¿¡æ¯
    Used to pass information between agents
    
    This TypedDict defines the state schema that flows through the LangGraph workflow.
    Each node can read from and write to this shared state.
    """
    # è¾“å…¥ | Inputs
    user_input: str  # ç”¨æˆ·çš„åˆå§‹è¾“å…¥ | User's initial input
    
    # ä¸­é—´ç»“æœ | Intermediate results
    research_result: Dict[str, Any]  # äº§å“ç ”ç©¶ç»“æœ | Product research result
    document_content: str  # ç”Ÿæˆçš„æ–‡æ¡£ | Generated document
    evaluation_result: Dict[str, Any]  # å¯è¡Œæ€§è¯„ä¼°ç»“æœ | Feasibility evaluation result
    
    # æœ€ç»ˆç»“æœ | Final results
    final_summary: Dict[str, Any]  # æœ€ç»ˆæ±‡æ€» | Final summary
    execution_log: List[str]  # æ‰§è¡Œæ—¥å¿— | Execution log
    
    # å…ƒæ•°æ® | Metadata
    timestamp: str  # æ—¶é—´æˆ³ | Timestamp
    execution_time: float  # æ‰§è¡Œæ—¶é—´ | Execution time


class LangGraphOrchestrator:
    """
    åŸºäº LangGraph çš„ç¼–æ’å™¨å®ç° | LangGraph-based Orchestrator Implementation
    
    ä¸»è¦ç‰¹ç‚¹ï¼š
    1. ä½¿ç”¨ LangGraph StateGraph ç®¡ç†å·¥ä½œæµ | Uses LangGraph StateGraph to manage workflow
    2. æ¸…æ™°çš„çŠ¶æ€è½¬ç§»å’Œè¾¹å®šä¹‰ | Clear state transitions and edge definitions
    3. æ”¯æŒæ¡ä»¶åˆ†æ”¯ï¼ˆå¯æ‰©å±•ï¼‰| Supports conditional branching (extensible)
    4. ä¾¿äºæ‰©å±•å’Œç»´æŠ¤ | Easy to extend and maintain
    
    é‡æ„è¯´æ˜ | Refactoring Notes:
    ====================
    å½“å‰å®ç° vs LangGraph å®ç°ï¼š
    
    å½“å‰å®ç°ï¼ˆæ‰‹åŠ¨é¡ºåºè°ƒç”¨ï¼‰ï¼š
    - æ‰‹åŠ¨æŒ‰é¡ºåºè°ƒç”¨èŠ‚ç‚¹å‡½æ•°
    - çŠ¶æ€é€šè¿‡å‡½æ•°å‚æ•°ä¼ é€’
    - æ²¡æœ‰å›¾ç»“æ„ï¼Œæ— æ³•å¯è§†åŒ–
    - éš¾ä»¥æ·»åŠ æ¡ä»¶åˆ†æ”¯æˆ–å¾ªç¯
    
    LangGraph å®ç°ï¼ˆçœŸæ­£çš„å›¾ç»“æ„ï¼‰ï¼š
    - ä½¿ç”¨ StateGraph åˆ›å»ºæœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰
    - çŠ¶æ€è‡ªåŠ¨åœ¨èŠ‚ç‚¹é—´ä¼ é€’
    - å¯ä»¥å¯è§†åŒ–æ•´ä¸ªå·¥ä½œæµå›¾
    - æ”¯æŒæ¡ä»¶è¾¹ã€å¾ªç¯ã€å¹¶è¡Œæ‰§è¡Œ
    - æ›´å¥½çš„é”™è¯¯å¤„ç†å’Œæ£€æŸ¥ç‚¹åŠŸèƒ½
    """
    
    def __init__(self, researcher, doc_assistant, evaluator, llm=None):
        """
        åˆå§‹åŒ– LangGraph ç¼–æ’å™¨ | Initialize LangGraph Orchestrator
        
        Args:
            researcher: äº§å“ç ”ç©¶å‘˜Agent | Product Researcher Agent
            doc_assistant: æ–‡æ¡£åŠ©æ‰‹Agent | Doc Assistant Agent
            evaluator: å¯è¡Œæ€§è¯„ä¼°å‘˜Agent | Feasibility Evaluator Agent
            llm: è¯­è¨€æ¨¡å‹å®ä¾‹ï¼ˆç”¨äºæ±‡æ€»ï¼‰| Language model instance (for summarization)
        """
        # å­˜å‚¨ä¸‰ä¸ªAgentçš„å®ä¾‹ | Store instances of three agents
        self.researcher = researcher
        self.doc_assistant = doc_assistant
        self.evaluator = evaluator
        
        # å­˜å‚¨ LLM å®ä¾‹ç”¨äºæ±‡æ€» | Store LLM instance for summarization
        if llm is None:
            from agents import init_llm
            self.llm = init_llm()
        else:
            self.llm = llm
        
        # è®°å½•æ‰§è¡Œæµç¨‹ | Record execution flow
        self.execution_flow = []
        
        # ç¼–æ’å™¨åç§° | Orchestrator name
        self.name = "LangGraph Orchestrator"
        
        # æ„å»º LangGraph å·¥ä½œæµ | Build LangGraph workflow
        self.workflow = self._build_workflow()
    
    def _build_workflow(self) -> StateGraph:
        """
        æ„å»º LangGraph å·¥ä½œæµå›¾ | Build LangGraph workflow graph
        
        Returns:
            ç¼–è¯‘åçš„ LangGraph åº”ç”¨ | Compiled LangGraph application
        """
        logger.info("Building LangGraph workflow...")
        
        # åˆ›å»ºçŠ¶æ€å›¾ | Create state graph
        workflow = StateGraph(OrchestratorState)
        logger.debug("Created StateGraph with OrchestratorState")
        
        # æ·»åŠ èŠ‚ç‚¹åˆ°å›¾ä¸­ | Add nodes to the graph
        # æ¯ä¸ªèŠ‚ç‚¹æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œæ¥æ”¶ state å¹¶è¿”å›æ›´æ–°åçš„ state
        logger.debug("Adding nodes to workflow...")
        workflow.add_node("researcher", self.researcher_node)
        logger.debug("  âœ“ Added node: researcher")
        workflow.add_node("doc_assistant", self.doc_assistant_node)
        logger.debug("  âœ“ Added node: doc_assistant")
        workflow.add_node("evaluator", self.evaluator_node)
        logger.debug("  âœ“ Added node: evaluator")
        workflow.add_node("aggregation", self.aggregation_node)
        logger.debug("  âœ“ Added node: aggregation")
        
        # å®šä¹‰å›¾çš„å…¥å£ç‚¹ | Define entry point of the graph
        workflow.set_entry_point("researcher")
        logger.debug("Set entry point: researcher")
        
        # æ·»åŠ è¾¹ï¼ˆå®šä¹‰èŠ‚ç‚¹é—´çš„è¿æ¥ï¼‰| Add edges (define connections between nodes)
        # è¿™äº›è¾¹å®šä¹‰äº†å·¥ä½œæµçš„æ‰§è¡Œé¡ºåº
        # æ–°é¡ºåº: researcher -> evaluator -> aggregation -> doc_assistant
        logger.debug("Adding edges to workflow...")
        workflow.add_edge("researcher", "evaluator")
        logger.debug("  âœ“ Edge: researcher -> evaluator")
        workflow.add_edge("evaluator", "aggregation")
        logger.debug("  âœ“ Edge: evaluator -> aggregation")
        workflow.add_edge("aggregation", "doc_assistant")
        logger.debug("  âœ“ Edge: aggregation -> doc_assistant")
        workflow.add_edge("doc_assistant", END)  # END æ˜¯ LangGraph çš„ç‰¹æ®ŠèŠ‚ç‚¹ï¼Œè¡¨ç¤ºå·¥ä½œæµç»“æŸ
        logger.debug("  âœ“ Edge: doc_assistant -> END")
        
        # ç¼–è¯‘å›¾ | Compile the graph
        # ç¼–è¯‘åä¼šè¿›è¡ŒéªŒè¯ï¼Œç¡®ä¿å›¾çš„å®Œæ•´æ€§
        logger.info("Compiling workflow graph...")
        app = workflow.compile()
        logger.info("âœ“ Workflow graph compiled successfully")
        
        # è®°å½•å›¾ç»“æ„ | Log graph structure
        try:
            graph = app.get_graph()
            logger.info(f"Graph nodes: {list(graph.nodes.keys())}")
            logger.info(f"Graph edges: {list(graph.edges)}")
        except Exception as e:
            logger.debug(f"Could not get graph structure: {e}")
        
        return app
    
    @log_function_call
    def researcher_node(self, state: OrchestratorState) -> OrchestratorState:
        """
        ç ”ç©¶å‘˜èŠ‚ç‚¹ | Researcher Node
        æ‰§è¡Œäº§å“ç ”ç©¶çš„å›¾èŠ‚ç‚¹
        Graph node that executes product research
        
        Args:
            state: å½“å‰ç¼–æ’å™¨çŠ¶æ€ | Current orchestrator state
            
        Returns:
            æ›´æ–°äº†research_resultçš„çŠ¶æ€ | State with updated research_result
        """
        logger.info("=" * 60)
        logger.info("NODE: researcher_node - Starting execution")
        logger.debug(f"State keys: {list(state.keys())}")
        logger.debug(f"User input length: {len(state.get('user_input', ''))}")
        
        # è®°å½•èŠ‚ç‚¹æ‰§è¡Œ | Log node execution
        log_message = "ğŸ“š Researcher Node: Executing product research"
        state["execution_log"].append(log_message)
        print(f"â†’ {log_message}")
        logger.info(log_message)
        
        # è°ƒç”¨ç ”ç©¶å‘˜Agent | Call researcher agent
        logger.info("Calling ProductResearcher.research()...")
        research_result = self.researcher.research(state["user_input"])
        logger.info("âœ“ ProductResearcher.research() completed")
        logger.debug(f"Research result keys: {list(research_result.get('research_result', {}).keys())}")
        
        # æ›´æ–°çŠ¶æ€ä¸­çš„ç ”ç©¶ç»“æœ | Update research result in state
        state["research_result"] = research_result["research_result"]
        logger.debug("Updated state['research_result']")
        
        # è®°å½•å®Œæˆ | Log completion
        completion_message = "âœ“ Researcher Node Completed"
        state["execution_log"].append(completion_message)
        print(f"âœ“ {completion_message}\n")
        logger.info(completion_message)
        logger.info("=" * 60)
        
        return state
    
    @log_function_call
    def doc_assistant_node(self, state: OrchestratorState) -> OrchestratorState:
        """
        æ–‡æ¡£åŠ©æ‰‹èŠ‚ç‚¹ | Doc Assistant Node
        æ‰§è¡Œäº§å“æ–‡æ¡£ç”Ÿæˆçš„å›¾èŠ‚ç‚¹ï¼ˆåŸºäºç ”ç©¶ã€è¯„ä¼°å’Œæ±‡æ€»ç»“æœï¼‰
        Graph node that executes product document generation (based on research, evaluation, and summary)
        
        Args:
            state: å½“å‰ç¼–æ’å™¨çŠ¶æ€ | Current orchestrator state
            
        Returns:
            æ›´æ–°äº†document_contentçš„çŠ¶æ€ | State with updated document_content
        """
        logger.info("=" * 60)
        logger.info("NODE: doc_assistant_node - Starting execution")
        
        # è®°å½•èŠ‚ç‚¹æ‰§è¡Œ | Log node execution
        log_message = "ğŸ“ Doc Assistant Node: Generating product documentation based on all results"
        state["execution_log"].append(log_message)
        print(f"â†’ {log_message}")
        logger.info(log_message)
        
        # è°ƒç”¨æ–‡æ¡£åŠ©æ‰‹Agent | Call doc assistant agent
        # æ³¨æ„ï¼šç°åœ¨ä½¿ç”¨ research_resultã€evaluation_result å’Œ final_summary
        logger.info("Calling DocAssistant.generate_doc_with_summary()...")
        
        # æ„å»ºåŒ…å«æ‰€æœ‰ä¿¡æ¯çš„ç ”ç©¶ç»“æœ | Build research result with all information
        enriched_research = {
            **state["research_result"],
            "evaluation_result": state["evaluation_result"],
            "final_summary": state["final_summary"]
        }
        
        doc_result = self.doc_assistant.generate_doc(
            state["user_input"],
            enriched_research
        )
        logger.info("âœ“ DocAssistant.generate_doc() completed")
        
        # æ›´æ–°çŠ¶æ€ä¸­çš„æ–‡æ¡£å†…å®¹ | Update document content in state
        state["document_content"] = doc_result["document"]
        logger.debug(f"Document length: {len(doc_result['document'])}")
        
        # è®°å½•å®Œæˆ | Log completion
        completion_message = "âœ“ Doc Assistant Node Completed"
        state["execution_log"].append(completion_message)
        print(f"âœ“ {completion_message}\n")
        logger.info(completion_message)
        logger.info("=" * 60)
        
        return state
    
    @log_function_call
    def evaluator_node(self, state: OrchestratorState) -> OrchestratorState:
        """
        å¯è¡Œæ€§è¯„ä¼°èŠ‚ç‚¹ | Feasibility Evaluator Node
        æ‰§è¡Œå¯è¡Œæ€§è¯„ä¼°çš„å›¾èŠ‚ç‚¹ï¼ˆåŸºäºç ”ç©¶ç»“æœï¼‰
        Graph node that executes feasibility evaluation (based on research results)
        
        Args:
            state: å½“å‰ç¼–æ’å™¨çŠ¶æ€ | Current orchestrator state
            
        Returns:
            æ›´æ–°äº†evaluation_resultçš„çŠ¶æ€ | State with updated evaluation_result
        """
        logger.info("=" * 60)
        logger.info("NODE: evaluator_node - Starting execution")
        
        # è®°å½•èŠ‚ç‚¹æ‰§è¡Œ | Log node execution
        log_message = "ğŸ” Evaluator Node: Conducting feasibility assessment based on research"
        state["execution_log"].append(log_message)
        print(f"â†’ {log_message}")
        logger.info(log_message)
        
        # è°ƒç”¨å¯è¡Œæ€§è¯„ä¼°Agent | Call feasibility evaluator agent
        # æ³¨æ„ï¼šç°åœ¨åªä½¿ç”¨ research_resultï¼Œä¸å†ä¾èµ– document_content
        logger.info("Calling FeasibilityEvaluator.evaluate()...")
        evaluation_result = self.evaluator.evaluate(
            state["user_input"],
            state["research_result"],
            ""  # ä¸å†ä½¿ç”¨ document_content
        )
        logger.info("âœ“ FeasibilityEvaluator.evaluate() completed")
        
        # æ›´æ–°çŠ¶æ€ä¸­çš„è¯„ä¼°ç»“æœ | Update evaluation result in state
        state["evaluation_result"] = evaluation_result["evaluation_result"]
        logger.debug(f"Evaluation keys: {list(evaluation_result['evaluation_result'].keys())}")
        
        # è®°å½•å®Œæˆ | Log completion
        completion_message = "âœ“ Evaluator Node Completed"
        state["execution_log"].append(completion_message)
        print(f"âœ“ {completion_message}\n")
        logger.info(completion_message)
        logger.info("=" * 60)
        
        return state
    
    @log_function_call
    def aggregation_node(self, state: OrchestratorState) -> OrchestratorState:
        """
        èšåˆèŠ‚ç‚¹ | Aggregation Node
        æ±‡æ€»ç ”ç©¶ç»“æœå’Œè¯„ä¼°ç»“æœå¹¶æç‚¼å…³é”®ç‚¹
        Aggregate research and evaluation results and extract key points
        
        Args:
            state: å½“å‰ç¼–æ’å™¨çŠ¶æ€ | Current orchestrator state
            
        Returns:
            æ›´æ–°äº†final_summaryçš„çŠ¶æ€ | State with updated final_summary
        """
        logger.info("=" * 60)
        logger.info("NODE: aggregation_node - Starting execution")
        
        # è®°å½•èŠ‚ç‚¹æ‰§è¡Œ | Log node execution
        log_message = "ğŸ¯ Aggregation Node: Summarizing research and evaluation results"
        state["execution_log"].append(log_message)
        print(f"â†’ {log_message}")
        logger.info(log_message)
        
        # ä½¿ç”¨ LLM è¿›è¡Œæ±‡æ€» | Use LLM for summarization
        from agents import parse_json_response
        
        # æ„å»ºæ±‡æ€»æç¤ºè¯ï¼ˆä¸å†ä½¿ç”¨ document_contentï¼‰| Build summarization prompt (no longer uses document_content)
        prompt = f"""
Based on the following outputs from research and evaluation, please extract key points and action recommendations:

User Requirement:
{state["user_input"]}

Product Researcher's Results:
{json.dumps(state["research_result"], ensure_ascii=False)}

Feasibility Evaluation Results:
{json.dumps(state["evaluation_result"], ensure_ascii=False)}

Please generate a high-level executive summary that includes:
1. Project Feasibility Score (1-10)
2. Core Value Propositions
3. Key Success Factors
4. Key Risks and Mitigation Strategies
5. Recommended Next Steps

Please return in JSON format with the following fields (all content must be in English):
- feasibility_score: Feasibility score (numeric value 1-10)
- value_propositions: Core value propositions (list of strings in English)
- success_factors: Key success factors (list of strings in English)
- risks_and_mitigations: Risks and mitigation strategies (list of strings in English)
- next_steps: Recommended next steps (list of strings in English)

IMPORTANT: All text content in the JSON response must be in English only.
"""
        
        # è°ƒç”¨ LLM è¿›è¡Œæ±‡æ€» | Call LLM for summarization
        summary_response = self.llm.invoke(prompt)
        
        # è§£æ JSON å“åº” | Parse JSON response
        summary = parse_json_response(summary_response, [
            "feasibility_score", "value_propositions", "success_factors",
            "risks_and_mitigations", "next_steps"
        ])
        
        # æ›´æ–°çŠ¶æ€ä¸­çš„æœ€ç»ˆæ±‡æ€» | Update final summary in state
        state["final_summary"] = summary
        logger.debug(f"Summary keys: {list(summary.keys())}")
        
        # è®°å½•å®Œæˆ | Log completion
        completion_message = "âœ“ Aggregation Node Completed"
        state["execution_log"].append(completion_message)
        print(f"âœ“ {completion_message}\n")
        logger.info(completion_message)
        logger.info("=" * 60)
        
        return state
    
    @log_function_call
    def execute_workflow(self, user_input: str) -> OrchestratorState:
        """
        æ‰§è¡Œå®Œæ•´çš„å·¥ä½œæµ | Execute complete workflow
        ä½¿ç”¨ LangGraph çš„ invoke æ–¹æ³•æ‰§è¡Œç¼–è¯‘åçš„å›¾
        Execute the compiled graph using LangGraph's invoke method
        
        Args:
            user_input: ç”¨æˆ·çš„äº§å“éœ€æ±‚è¾“å…¥ | User's product requirement input
            
        Returns:
            æœ€ç»ˆçš„ç¼–æ’å™¨çŠ¶æ€ | Final orchestrator state
        """
        logger.info("=" * 80)
        logger.info("EXECUTING LANGGRAPH WORKFLOW")
        logger.info("=" * 80)
        
        # åˆ›å»ºåˆå§‹çŠ¶æ€ | Create initial state
        logger.info("Creating initial state...")
        initial_state = self.create_initial_state(user_input)
        logger.debug(f"Initial state keys: {list(initial_state.keys())}")
        
        # è®°å½•å·¥ä½œæµå¼€å§‹ | Log workflow start
        start_time = datetime.now()
        logger.info(f"Workflow started at: {start_time.isoformat()}")
        
        print("\n" + "="*80)
        print("ğŸŒ LangGraph Orchestration Workflow")
        print("ğŸŒ LangGraph ç¼–æ’å·¥ä½œæµ")
        print("="*80 + "\n")
        
        # ä½¿ç”¨ LangGraph çš„ invoke æ–¹æ³•æ‰§è¡Œå·¥ä½œæµ
        # LangGraph ä¼šè‡ªåŠ¨ï¼š
        # 1. æŒ‰ç…§å®šä¹‰çš„è¾¹é¡ºåºæ‰§è¡ŒèŠ‚ç‚¹
        # 2. åœ¨èŠ‚ç‚¹é—´ä¼ é€’çŠ¶æ€
        # 3. å¤„ç†é”™è¯¯å’Œå¼‚å¸¸
        # 4. æ”¯æŒæµå¼è¾“å‡ºï¼ˆå¦‚æœä½¿ç”¨ stream æ–¹æ³•ï¼‰
        logger.info("Invoking LangGraph workflow...")
        logger.info("Workflow execution flow:")
        logger.info("  START -> researcher -> evaluator -> aggregation -> doc_assistant -> END")
        
        try:
            final_state = self.workflow.invoke(initial_state)
            logger.info("âœ“ LangGraph workflow execution completed successfully")
        except Exception as e:
            logger.error(f"âœ— LangGraph workflow execution failed: {str(e)}", exc_info=True)
            raise
        
        # è®¡ç®—æ‰§è¡Œæ—¶é—´ | Calculate execution time
        end_time = datetime.now()
        execution_time = (end_time - start_time).total_seconds()
        final_state["execution_time"] = execution_time
        logger.info(f"Workflow execution time: {execution_time:.2f} seconds")
        logger.info(f"Workflow completed at: {end_time.isoformat()}")
        logger.info("=" * 80)
        
        return final_state
    
    def stream_workflow(self, user_input: str):
        """
        æµå¼æ‰§è¡Œå·¥ä½œæµ | Stream workflow execution
        ä½¿ç”¨ LangGraph çš„ stream æ–¹æ³•ï¼Œå¯ä»¥å®æ—¶çœ‹åˆ°æ¯ä¸ªèŠ‚ç‚¹çš„æ‰§è¡Œ
        
        Args:
            user_input: ç”¨æˆ·çš„äº§å“éœ€æ±‚è¾“å…¥ | User's product requirement input
            
        Yields:
            æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œåçš„çŠ¶æ€ | State after each node execution
        """
        # åˆ›å»ºåˆå§‹çŠ¶æ€ | Create initial state
        initial_state = self.create_initial_state(user_input)
        
        # ä½¿ç”¨ stream æ–¹æ³•æµå¼æ‰§è¡Œ
        # è¿™ä¼šè¿”å›ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œæ¯æ¬¡ yield ä¸€ä¸ªèŠ‚ç‚¹çš„æ‰§è¡Œç»“æœ
        for state in self.workflow.stream(initial_state):
            yield state
    
    def create_initial_state(self, user_input: str) -> OrchestratorState:
        """
        åˆ›å»ºåˆå§‹çŠ¶æ€ | Create initial state
        
        Args:
            user_input: ç”¨æˆ·çš„äº§å“éœ€æ±‚è¾“å…¥ | User's product requirement input
            
        Returns:
            åˆå§‹åŒ–çš„ç¼–æ’å™¨çŠ¶æ€ | Initialized orchestrator state
        """
        # åˆ›å»ºåˆå§‹çŠ¶æ€å­—å…¸ | Create initial state dictionary
        initial_state: OrchestratorState = {
            "user_input": user_input,  # ç”¨æˆ·è¾“å…¥ | User input
            "research_result": {},  # åˆå§‹åŒ–ä¸ºç©º | Initialize as empty
            "document_content": "",  # åˆå§‹åŒ–ä¸ºç©º | Initialize as empty
            "evaluation_result": {},  # åˆå§‹åŒ–ä¸ºç©º | Initialize as empty
            "final_summary": {},  # åˆå§‹åŒ–ä¸ºç©º | Initialize as empty
            "execution_log": [],  # åˆå§‹åŒ–ä¸ºç©ºæ—¥å¿—åˆ—è¡¨ | Initialize as empty log list
            "timestamp": datetime.now().isoformat(),  # è®°å½•æ—¶é—´æˆ³ | Record timestamp
            "execution_time": 0.0  # æ‰§è¡Œæ—¶é—´ | Execution time
        }
        
        return initial_state
    
    def visualize_workflow_graph(self):
        """
        å¯è§†åŒ–å·¥ä½œæµå›¾ | Visualize workflow graph
        ä½¿ç”¨ LangGraph çš„å†…ç½®å¯è§†åŒ–åŠŸèƒ½
        Use LangGraph's built-in visualization capabilities
        """
        print("\n" + "="*80)
        print("ğŸ“Š LangGraph Workflow Structure")
        print("ğŸ“Š LangGraph å·¥ä½œæµç»“æ„")
        print("="*80 + "\n")
        
        # LangGraph æä¾›äº† get_graph() æ–¹æ³•æ¥è·å–å›¾çš„è¡¨ç¤º
        # å¯ä»¥ç”¨äºå¯è§†åŒ–æˆ–è°ƒè¯•
        try:
            graph = self.workflow.get_graph()
            print("Graph Nodes:", list(graph.nodes.keys()))
            print("Graph Edges:", list(graph.edges))
            print("\n")
        except:
            pass
        
        # ç»˜åˆ¶å·¥ä½œæµå›¾ | Draw workflow graph
        graph_visualization = """
        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        â•‘                    LangGraph Orchestration Flow                         â•‘
        â•‘                    LangGraph ç¼–æ’å·¥ä½œæµ                                 â•‘
        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
                                    START
                                     â”‚
                                     â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   INPUT STATE          â”‚
                        â”‚  (user_input)          â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  RESEARCHER_NODE       â”‚
                        â”‚  â€¢ Conduct Research    â”‚
                        â”‚  â€¢ Market Analysis     â”‚
                        â”‚  Output: research_     â”‚
                        â”‚           result       â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  EVALUATOR_NODE        â”‚
                        â”‚  â€¢ Feasibility Check   â”‚
                        â”‚  â€¢ Risk Assessment     â”‚
                        â”‚  Output: evaluation_   â”‚
                        â”‚          result        â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  AGGREGATION_NODE      â”‚
                        â”‚  â€¢ Summarize Results   â”‚
                        â”‚  â€¢ Synthesize Output   â”‚
                        â”‚  Output: final_        â”‚
                        â”‚          summary       â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  DOC_ASSISTANT_NODE    â”‚
                        â”‚  â€¢ Generate Document   â”‚
                        â”‚  â€¢ PRD Creation        â”‚
                        â”‚  Output: document_     â”‚
                        â”‚          content       â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   FINAL STATE          â”‚
                        â”‚  (all outputs)         â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                                    END
        
        
        State Flow Diagram - çŠ¶æ€æµå›¾ï¼š
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        user_input
             â†“
        research_result  â†â”€â”€ Researcher Node
             â†“
        evaluation_result  â†â”€â”€ Evaluator Node (uses research_result)
             â†“
        final_summary  â†â”€â”€ Aggregation Node (uses research_result + evaluation_result)
             â†“
        document_content  â†â”€â”€ Doc Assistant Node (uses all previous outputs)
        
        
        Node Dependencies - èŠ‚ç‚¹ä¾èµ–å…³ç³»ï¼š
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        Researcher Node:
          Inputs: user_input
          Outputs: research_result
        
        Evaluator Node:
          Inputs: user_input, research_result
          Outputs: evaluation_result
        
        Aggregation Node:
          Inputs: research_result, evaluation_result
          Outputs: final_summary
        
        Doc Assistant Node:
          Inputs: user_input, research_result, evaluation_result, final_summary
          Outputs: document_content
        
        
        LangGraph Features Used - ä½¿ç”¨çš„ LangGraph ç‰¹æ€§ï¼š
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        âœ… StateGraph: åˆ›å»ºçŠ¶æ€å›¾
        âœ… add_node(): æ·»åŠ èŠ‚ç‚¹åˆ°å›¾
        âœ… add_edge(): å®šä¹‰èŠ‚ç‚¹é—´çš„è¾¹
        âœ… set_entry_point(): è®¾ç½®å…¥å£ç‚¹
        âœ… compile(): ç¼–è¯‘å›¾
        âœ… invoke(): æ‰§è¡Œå·¥ä½œæµ
        âœ… stream(): æµå¼æ‰§è¡Œï¼ˆå¯é€‰ï¼‰
        """
        
        print(graph_visualization)
        print("="*80 + "\n")
